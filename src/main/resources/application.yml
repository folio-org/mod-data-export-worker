server:
  port: 8081
  tomcat.threads.max: 100
spring:
  application:
    name: mod-data-export-worker
  jackson:
    default-property-inclusion: non_empty
    deserialization:
      fail-on-unknown-properties: false
  kafka:
    bootstrap-servers: ${KAFKA_HOST:localhost}:${KAFKA_PORT:9092}
    listener:
      concurrency: ${KAFKA_CONCURRENCY_LEVEL:30}
    consumer:
      auto-offset-reset: latest
      enable-auto-commit: true
  datasource:
    username: ${DB_USERNAME:folio_admin}
    password: ${DB_PASSWORD:folio_admin}
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_DATABASE:okapi_modules}
  sql:
    init:
      continue-on-error: true
  jpa:
    open-in-view: false
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    hibernate:
      ddl-auto: none
      naming:
        physical-strategy: org.hibernate.boot.model.naming.CamelCaseToUnderscoresNamingStrategy
        implicit-strategy: org.springframework.boot.orm.jpa.hibernate.SpringImplicitNamingStrategy
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
    show-sql: false
  batch:
    job:
      enabled: false
    jdbc:
      initialize-schema: never
  liquibase:
    changeLog: classpath:db/changelog/data-export-worker-changelog-master.xml
    enabled: true
  servlet:
    multipart:
      max-file-size: ${MAX_UPLOADED_FILE_SIZE:40MB}
      max-request-size: ${MAX_UPLOADED_FILE_SIZE:40MB}
  cloud:
    openfeign:
      okhttp:
        enabled: true
management:
  endpoints:
    web:
      base-path: /admin
      exposure:
        include: health, loggers
  endpoint:
    loggers:
      enabled: true
  influx:
    metrics:
      export:
        enabled: false
feign:
  client:
    config:
      default:
        loggerLevel: basic
application:
  kafka:
    topic-configuration:
      "data-export.job.update":
        partitions: ${DATA_EXPORT_JOB_UPDATE_TOPIC_PARTITIONS:50}
      "edi-export-history.create":
        partitions: ${EDI_EXPORT_HISTORY_TOPIC_PARTITIONS:1}
    topic-pattern: ${ENV:folio}.(.*\.)?data-export.job.command
    group-id: ${ENV:folio}-mod-data-export-worker-events-group
  minio-remote:
    endpoint: ${S3_URL:http://127.0.0.1:9000/}
    region: ${S3_REGION:}
    bucket: ${S3_BUCKET:}
    accessKey: ${S3_ACCESS_KEY_ID:}
    secretKey: ${S3_SECRET_ACCESS_KEY:}
    composeWithAwsSdk: ${S3_IS_AWS:false}
    subPath: ${S3_SUB_PATH:mod-data-export-worker/remote}
    url-expiration-time-in-seconds: ${URL_EXPIRATION_TIME:604800} # 7 days
  minio-local:
    endpoint: ${S3_URL:http://127.0.0.1:9000/}
    region: ${S3_REGION:}
    bucket: ${S3_BUCKET:}
    accessKey: ${S3_ACCESS_KEY_ID:}
    secretKey: ${S3_SECRET_ACCESS_KEY:}
    composeWithAwsSdk: ${S3_IS_AWS:false}
    subPath: ${S3_LOCAL_SUB_PATH:mod-data-export-worker/local}
    url-expiration-time-in-seconds: ${URL_EXPIRATION_TIME:604800} # 7 days
  ftp:
    bufferSize: 1048576 #that 1024 * 1024
    defaultPort: 21
    defaultTimeout: 30000
    controlKeepAliveTimeout: 30
  bucket:
    size: ${BUCKET_SIZE:50}
  e-holdings-batch:
    job-chunk-size: ${E_HOLDINGS_BATCH_JOB_CHUNK_SIZE:100}
    kb-ebsco-chunk-size: ${E_HOLDINGS_BATCH_KB_EBSCO_CHUNK_SIZE:100}
  authority-control-batch:
    job-chunk-size: ${AUTHORITY_CONTROL_BATCH_JOB_CHUNK_SIZE:100}
    entities-links-chunk-size: ${AUTHORITY_CONTROL_BATCH_ENTITIES_LINKS_CHUNK_SIZE:100}
  chunks: ${CHUNKS:100}
  core-pool-size: ${CORE_POOL_SIZE:10}
  max-pool-size: ${MAX_POOL_SIZE:10}
  platform: ${PLATFORM:okapi}

folio:
  tenant:
    validation:
      enabled: true
logging:
  level:
    org.folio.dew.client.*: debug
    org.springframework.core.log.*: ERROR
    org.apache.kafka.*: ERROR
